from pathlib import Path
from joblib import Memory
import h5py
import numpy as np
from scipy.signal import butter, filtfilt, iirnotch, find_peaks, ricker, cwt
import matplotlib.pyplot as plt
from sklearn.decomposition import FastICA


DATA_DIR = Path.cwd() / 'data/' # EMG signals
CACHE_DIR = Path.cwd() / 'cache/' # cache previously done computations (via joblib)

memory = Memory(CACHE_DIR)





def butter_bandpass(lowcut, highcut, fs, order=5):
    nyq = 0.5 * fs
    b, a = butter(order, [lowcut/ nyq, highcut/ nyq], btype='band', analog=False)
    return b, a

def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):
    b, a = butter_bandpass(lowcut, highcut, fs, order=order)
    y = filtfilt(b, a, data)
    return y

def notch(notch_freq, samp_freq, quality_factor=30):
    b, a = iirnotch(notch_freq, quality_factor, samp_freq)
    return b, a

def notch_filter(data, notch_fs, fs, q=30):
    b, a = notch(notch_fs, fs, q)
    y = filtfilt(b, a, data)
    return y

@memory.cache
def filt_GRID(data, lowcut=20, highcut=500, fs=4000, order=3, notch_fs = 50, notch_q = 30):
    filt_out = np.zeros_like(data)
    for i in range(data.shape[0]):
        filt_out[i,:] = notch_filter(butter_bandpass_filter(data[i,:], lowcut, highcut, fs, order=order), notch_fs, fs, notch_q)
    return filt_out



def loadmat(filename):
    file = h5py.File(filename, 'r')
    return np.asarray(file['grid_crds']), np.asarray(file['out_mat'])

if1_grid_crds, if1_out_mat = loadmat(DATA_DIR / r'increasing-force-1.mat')
if2_grid_crds, if2_out_mat = loadmat(DATA_DIR / r'increasing-force-2.mat')
sf1_grid_crds, sf1_out_mat = loadmat(DATA_DIR / r'steady-force-1.mat')

emg = sf1_out_mat

print(emg.shape)





filtered_if1_out_mat = filt_GRID(emg.T).T


def plot_emg(emg, time_bounds=None, step_size=8, figsize=None):
    num_rows = emg.shape[1] // step_size

    if figsize is None:
        print(num_rows)
        figsize = [20, (20 * num_rows) // 8]
        print(figsize)

    if time_bounds is None:
        time_bounds = (10000, 10000+1500)

    left, right = time_bounds
    assert 0 <= left <= right

    fig, ax = plt.subplots(nrows=num_rows, figsize=figsize)
    for i in range(0, emg.shape[1] // step_size):
        ax[i].plot(emg[:, i])
        ax[i].set_xlim(left=left, right=right)
        ax[i].set_ylabel(f"Electrode {i*step_size}")
    
    
    return fig, ax


fig, ax = plot_emg(filtered_if1_out_mat, step_size=1, time_bounds=(0, 1500))
plt.show()






fastica = FastICA(n_components=filtered_if1_out_mat.shape[1])
ica_fit = memory.cache(fastica.fit)


fastica_model = ica_fit(filtered_if1_out_mat)
IC = fastica_model.transform(filtered_if1_out_mat)
print(IC)


fig, ax = plot_emg(IC, step_size=1, time_bounds=(0, 1500))
plt.show()


# filtered_IC = butter_bandpass_filter(IC.T, lowcut=50, highcut=150, fs=4000).T

# fig, ax = plt.subplots(nrows=filtered_IC.shape[1]//8, figsize=[10, 10])
# for i in range(0, filtered_IC.shape[1]//8):
#     ax[i].plot(filtered_IC[:, i])
#     ax[i].set_xlim(left=10000, right=10000+1500)
# plt.show()


wavelet_convolved_IC = []
WIDTHS = np.arange(5, 25, 1) # roughly estimated based on total duration of Ricker wavelet, wavelet width, and durations of MUAP pulses

for i in range(IC.shape[1]):
    wavelet_convolved_IC.append(cwt(IC[:, i], ricker, WIDTHS))

wavelet_convolved_IC = np.asarray(wavelet_convolved_IC)
wavelet_convolved_IC = np.moveaxis(wavelet_convolved_IC, [0, 1, 2], [0, 2, 1])
print(wavelet_convolved_IC.shape) # shape is electrode number, time, wavelet width


fig, ax = plt.subplots(nrows=wavelet_convolved_IC.shape[0]//16, figsize=[10, 10])
for i in range(0, wavelet_convolved_IC.shape[0]//16):
    ax[i].plot(IC[:, i])
    ax[i].plot(wavelet_convolved_IC[i, :, 10], 'red')
    peaks, _ = find_peaks(wavelet_convolved_IC[i, :, 10])
    
    ax[i].set_xlim(left=10000, right=10000+1500)
plt.show()


@memory.cache
def nms(peaks, confs, temp_threshold) -> list[int]:
    keep_ids = []
    order_ids = np.argsort(-confs)
    for idx in order_ids:
        suppressed = False
        for keep_idx in keep_ids:
            if abs(peaks[keep_idx] - peaks[idx]) < temp_threshold:
                suppressed = True
                break
        if not suppressed:
            keep_ids.append(idx)
    return keep_ids





from joblib import Parallel, delayed

parallel = Parallel(n_jobs=6)


def get_firing_times(i):
    ic_peaks = []
    ic_confs = []
    for j in range(wavelet_convolved_IC.shape[2]):
        sig = np.abs(wavelet_convolved_IC[i, :, j])
        peaks, _ = find_peaks(sig)
        confs = sig[peaks]
        ic_peaks.extend(peaks)
        ic_confs.extend(confs)
    ic_peaks = np.asarray(ic_peaks)
    ic_confs = np.asarray(ic_confs)

    keep_ids = nms(ic_peaks, ic_confs, temp_threshold=50)
    keep_peaks = ic_peaks[keep_ids]
    keep_peaks = np.sort(keep_peaks)
    
    return keep_peaks

firing_times = parallel(delayed(get_firing_times)(i) for i in range(wavelet_convolved_IC.shape[0]))


"""
firing_times = []

for i in range(wavelet_convolved_IC.shape[0]):
    ic_peaks = []
    ic_confs = []
    for j in range(wavelet_convolved_IC.shape[2]):
        sig = wavelet_convolved_IC[i, :, j]
        peaks, _ = find_peaks(sig)
        confs = sig[peaks]
        ic_peaks.extend(peaks)
        ic_confs.extend(confs)
    ic_peaks = np.asarray(ic_peaks)
    ic_confs = np.asarray(ic_confs)

    keep_ids = nms(ic_peaks, ic_confs, temp_threshold=50)
    keep_peaks = ic_peaks[keep_ids]
    keep_peaks = np.sort(keep_peaks)
    firing_times.append(keep_peaks)
    """


step_size = 1
num_rows = emg.shape[1] // step_size

print(num_rows)
figsize = [20, (20 * num_rows) // 8]
print(figsize)

left = 10000
right = left + 1500


fig, ax = plt.subplots(nrows=num_rows, figsize=figsize)
print(IC.shape)

for i in range(0, IC.shape[1] // step_size):

    ft = firing_times[i]
    mask = np.zeros(IC.shape[0])
    mask[ft] = 1
    peak_amps = IC[:, i*step_size] * mask
    peak_amps[peak_amps == 0] = np.NaN
    ax[i].stem(peak_amps, 'red')
    ax[i].plot(IC[:, i*step_size])

    ax[i].set_xlim(left=left, right=right)
    ax[i].set_ylabel(f"Ind. Comp. {i*step_size}")
    


for ft in firing_times[:]:
    isi = ft[1:] - ft[:-1]
    print(np.mean(isi) / 4)
    isi = isi / 4 # sampling period is 0.25 ms
    plt.figure()
    plt.hist(isi)
    plt.xlabel("Firing Time (ms)")


with open('sf1_out_mat.txt', 'w') as file:
    for i in range(wavelet_convolved_IC.shape[0]):
        for firing_time in firing_times[i][:-1]:
            file.write(f'{firing_time},')
        file.write(f'{firing_times[-1][-1]}\n')


np.savetxt("sf1_out_mat.csv", fastica_model.mixing_)
